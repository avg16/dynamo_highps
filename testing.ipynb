{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d067829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SAP ERP with parameters: {'server': 'erp.example.com', 'username': 'api_user', 'password': 'api_password', 'database': 'prod_db'}\n",
      "Failed to parse mapping JSON from Gemini response: ```json\n",
      "{\n",
      "  \"mapping\": {\n",
      "    \"customer_id\": \"id\",\n",
      "    \"customer_name\": \"name\",\n",
      "    \"email\": \"contact_email\",\n",
      "    \"phone\": \"contact_phone\",\n",
      "    \"address\": \"address\",\n",
      "    \"registration_date\": \"customer_since\",\n",
      "    \"customer_type\": \"segment\", \n",
      "    \"industry\": null,  // No direct mapping, could potentially be used to derive 'segment' in a more complex scenario\n",
      "    \"status\": \"\" // Left empty as no corresponding field exists in the source data\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Data extraction and mapping completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class ERPDataMapper:\n",
    "    \"\"\"\n",
    "    A class for extracting, mapping, and standardizing data from various ERP systems\n",
    "    using Google's Gemini LLM for intelligent data transformation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gemini_api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the ERP Data Mapper.\n",
    "        \n",
    "        Args:\n",
    "            gemini_api_key: API key for Google's Gemini LLM\n",
    "        \"\"\"\n",
    "        # Load environment variables if API key is not provided\n",
    "        if not gemini_api_key:\n",
    "            load_dotenv()\n",
    "            gemini_api_key = \"AIzaSyCyJBxlzOnVrUIMvx6gw66i19Y32lDGNP4\"\n",
    "            \n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"Gemini API key is required. Set it in .env file or pass directly.\")\n",
    "            \n",
    "        # Configure Gemini API\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        \n",
    "        # Set up Gemini model\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "        \n",
    "        # Define standard data schema templates\n",
    "        self.standard_schemas = {\n",
    "            \"customer\": {\n",
    "                \"id\": \"\",\n",
    "                \"name\": \"\",\n",
    "                \"contact_email\": \"\",\n",
    "                \"contact_phone\": \"\",\n",
    "                \"address\": \"\",\n",
    "                \"customer_since\": \"\",\n",
    "                \"status\": \"\",\n",
    "                \"segment\": \"\"\n",
    "            },\n",
    "            \"product\": {\n",
    "                \"id\": \"\",\n",
    "                \"name\": \"\",\n",
    "                \"description\": \"\",\n",
    "                \"price\": \"\",\n",
    "                \"category\": \"\",\n",
    "                \"sku\": \"\",\n",
    "                \"stock_quantity\": \"\",\n",
    "                \"unit\": \"\"\n",
    "            },\n",
    "            \"invoice\": {\n",
    "                \"id\": \"\",\n",
    "                \"customer_id\": \"\",\n",
    "                \"date\": \"\",\n",
    "                \"due_date\": \"\",\n",
    "                \"total_amount\": \"\",\n",
    "                \"tax_amount\": \"\",\n",
    "                \"status\": \"\",\n",
    "                \"line_items\": []\n",
    "            },\n",
    "            \"employee\": {\n",
    "                \"id\": \"\",\n",
    "                \"name\": \"\",\n",
    "                \"department\": \"\",\n",
    "                \"position\": \"\",\n",
    "                \"email\": \"\",\n",
    "                \"phone\": \"\",\n",
    "                \"hire_date\": \"\",\n",
    "                \"manager_id\": \"\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def connect_to_erp(self, erp_type: str, connection_params: Dict[str, Any]) -> bool:\n",
    "        \"\"\"\n",
    "        Connect to the specified ERP system.\n",
    "        \n",
    "        Args:\n",
    "            erp_type: Type of ERP system (e.g., 'sap', 'oracle', 'microsoft_dynamics', 'odoo')\n",
    "            connection_params: Connection parameters specific to the ERP system\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if connection was successful, False otherwise\n",
    "        \"\"\"\n",
    "        self.erp_type = erp_type.lower()\n",
    "        self.connection_params = connection_params\n",
    "        \n",
    "        # Implement connection logic based on ERP type\n",
    "        try:\n",
    "            if self.erp_type == \"sap\":\n",
    "                # SAP connection logic would go here\n",
    "                # This is a placeholder - real implementation would use SAP-specific libraries\n",
    "                print(f\"Connecting to SAP ERP with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"sap\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            elif self.erp_type == \"oracle\":\n",
    "                # Oracle connection logic\n",
    "                print(f\"Connecting to Oracle ERP with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"oracle\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            elif self.erp_type == \"microsoft_dynamics\":\n",
    "                # Microsoft Dynamics connection logic\n",
    "                print(f\"Connecting to Microsoft Dynamics with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"microsoft_dynamics\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            elif self.erp_type == \"odoo\":\n",
    "                # Odoo connection logic\n",
    "                print(f\"Connecting to Odoo with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"odoo\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            elif self.erp_type == \"quickbooks\":\n",
    "                # QuickBooks connection logic\n",
    "                print(f\"Connecting to QuickBooks with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"quickbooks\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            elif self.erp_type == \"netsuite\":\n",
    "                # NetSuite connection logic\n",
    "                print(f\"Connecting to NetSuite with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"netsuite\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            elif self.erp_type == \"api\":\n",
    "                # Generic API connection\n",
    "                print(f\"Connecting to API with parameters: {connection_params}\")\n",
    "                self.connection = {\"type\": \"api\", \"status\": \"connected\"}\n",
    "                return True\n",
    "                \n",
    "            else:\n",
    "                print(f\"Unsupported ERP type: {self.erp_type}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error connecting to {self.erp_type}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def extract_data(self, data_type: str, query_params: Dict[str, Any] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract data from the connected ERP system.\n",
    "        \n",
    "        Args:\n",
    "            data_type: Type of data to extract (e.g., 'customers', 'products', 'invoices')\n",
    "            query_params: Optional parameters to filter the data\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing the extracted data\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'connection'):\n",
    "            raise ValueError(\"Not connected to any ERP system. Call connect_to_erp() first.\")\n",
    "        \n",
    "        # This is a mock implementation - real implementation would use \n",
    "        # ERP-specific APIs or database queries\n",
    "        try:\n",
    "            # Example mock data - in a real scenario, this would pull from the ERP\n",
    "            if data_type == \"customers\":\n",
    "                # Mock customer data\n",
    "                customers = [\n",
    "                    {\"customer_id\": \"C001\", \"customer_name\": \"Acme Corp\", \"email\": \"contact@acme.com\", \n",
    "                     \"phone\": \"555-123-4567\", \"address\": \"123 Main St\", \"registration_date\": \"2020-01-15\", \n",
    "                     \"customer_type\": \"Corporate\", \"industry\": \"Manufacturing\"},\n",
    "                    {\"customer_id\": \"C002\", \"customer_name\": \"TechSolutions\", \"email\": \"info@techsolutions.com\", \n",
    "                     \"phone\": \"555-987-6543\", \"address\": \"456 Tech Blvd\", \"registration_date\": \"2019-05-20\", \n",
    "                     \"customer_type\": \"Corporate\", \"industry\": \"IT Services\"}\n",
    "                ]\n",
    "                return customers\n",
    "                \n",
    "            elif data_type == \"products\":\n",
    "                # Mock product data\n",
    "                products = [\n",
    "                    {\"product_id\": \"P001\", \"product_name\": \"Widget Pro\", \"description\": \"Professional grade widget\", \n",
    "                     \"unit_price\": 29.99, \"category\": \"Widgets\", \"product_code\": \"WDG-PRO\", \"current_stock\": 150, \n",
    "                     \"measurement\": \"units\"},\n",
    "                    {\"product_id\": \"P002\", \"product_name\": \"Gadget Plus\", \"description\": \"Enhanced gadget\", \n",
    "                     \"unit_price\": 49.99, \"category\": \"Gadgets\", \"product_code\": \"GDG-PLS\", \"current_stock\": 75, \n",
    "                     \"measurement\": \"units\"}\n",
    "                ]\n",
    "                return products\n",
    "                \n",
    "            elif data_type == \"invoices\":\n",
    "                # Mock invoice data\n",
    "                invoices = [\n",
    "                    {\"invoice_id\": \"INV001\", \"customer_id\": \"C001\", \"invoice_date\": \"2023-06-15\", \n",
    "                     \"payment_due\": \"2023-07-15\", \"invoice_total\": 299.90, \"tax\": 29.99, \n",
    "                     \"invoice_status\": \"Paid\", \"items\": [\n",
    "                         {\"product_id\": \"P001\", \"quantity\": 10, \"price\": 29.99}\n",
    "                     ]},\n",
    "                    {\"invoice_id\": \"INV002\", \"customer_id\": \"C002\", \"invoice_date\": \"2023-06-20\", \n",
    "                     \"payment_due\": \"2023-07-20\", \"invoice_total\": 499.90, \"tax\": 49.99, \n",
    "                     \"invoice_status\": \"Pending\", \"items\": [\n",
    "                         {\"product_id\": \"P002\", \"quantity\": 10, \"price\": 49.99}\n",
    "                     ]}\n",
    "                ]\n",
    "                return invoices\n",
    "                \n",
    "            elif data_type == \"employees\":\n",
    "                # Mock employee data\n",
    "                employees = [\n",
    "                    {\"employee_id\": \"E001\", \"full_name\": \"John Smith\", \"dept\": \"Sales\", \n",
    "                     \"job_title\": \"Sales Manager\", \"work_email\": \"john.smith@company.com\", \n",
    "                     \"work_phone\": \"555-111-2222\", \"start_date\": \"2018-03-15\", \"reports_to\": \"E005\"},\n",
    "                    {\"employee_id\": \"E002\", \"full_name\": \"Jane Doe\", \"dept\": \"Marketing\", \n",
    "                     \"job_title\": \"Marketing Specialist\", \"work_email\": \"jane.doe@company.com\", \n",
    "                     \"work_phone\": \"555-333-4444\", \"start_date\": \"2019-08-01\", \"reports_to\": \"E006\"}\n",
    "                ]\n",
    "                return employees\n",
    "                \n",
    "            else:\n",
    "                print(f\"Unsupported data type: {data_type}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {data_type} data: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def map_data_with_gemini(self, \n",
    "                             data: List[Dict[str, Any]], \n",
    "                             target_schema: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Use Gemini LLM to map data from the ERP format to the standard schema.\n",
    "        \n",
    "        Args:\n",
    "            data: List of data records from the ERP system\n",
    "            target_schema: Target schema name (e.g., 'customer', 'product')\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries in the standardized format\n",
    "        \"\"\"\n",
    "        if not data:\n",
    "            return []\n",
    "        \n",
    "        if target_schema not in self.standard_schemas:\n",
    "            raise ValueError(f\"Unknown target schema: {target_schema}\")\n",
    "        \n",
    "        # Prepare standard schema template\n",
    "        standard_template = self.standard_schemas[target_schema]\n",
    "        \n",
    "        # Prepare prompt for Gemini\n",
    "        prompt = f\"\"\"\n",
    "        You are a data mapping expert. Map the following data from an {self.erp_type.upper()} ERP system \n",
    "        to the standard {target_schema} schema shown below.\n",
    "        \n",
    "        Source Data (from {self.erp_type.upper()} ERP):\n",
    "        {json.dumps(data[0], indent=2)}\n",
    "        \n",
    "        Target Schema:\n",
    "        {json.dumps(standard_template, indent=2)}\n",
    "        \n",
    "        Generate a JSON mapping that shows which source fields map to which target fields. \n",
    "        Use the exact field names from the source data and target schema. If a field doesn't have \n",
    "        a direct mapping, indicate that it should be left empty or derive it from other fields if possible.\n",
    "        \n",
    "        Format your response as valid JSON in this format:\n",
    "        {{\"mapping\": {{\"source_field1\": \"target_field1\", \"source_field2\": \"target_field2\", ...}}}}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate mapping using Gemini\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            mapping_text = response.text\n",
    "            \n",
    "            # Extract JSON from the response\n",
    "            try:\n",
    "                # Try to find JSON in the response if it's formatted with markdown or other text\n",
    "                json_start = mapping_text.find('{')\n",
    "                json_end = mapping_text.rfind('}') + 1\n",
    "                if json_start >= 0 and json_end > json_start:\n",
    "                    mapping_json = json.loads(mapping_text[json_start:json_end])\n",
    "                else:\n",
    "                    mapping_json = json.loads(mapping_text)\n",
    "                \n",
    "                field_mapping = mapping_json.get('mapping', {})\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse mapping JSON from Gemini response: {mapping_text}\")\n",
    "                # Fallback to simple field name matching if JSON parsing fails\n",
    "                field_mapping = {}\n",
    "                for source_field in data[0].keys():\n",
    "                    for target_field in standard_template.keys():\n",
    "                        if source_field.lower() in target_field.lower() or target_field.lower() in source_field.lower():\n",
    "                            field_mapping[source_field] = target_field\n",
    "            \n",
    "            # Apply the mapping to all data records\n",
    "            mapped_data = []\n",
    "            for record in data:\n",
    "                mapped_record = dict(standard_template)  # Start with empty template\n",
    "                \n",
    "                # Apply direct field mappings\n",
    "                for source_field, target_field in field_mapping.items():\n",
    "                    if source_field in record and target_field in mapped_record:\n",
    "                        mapped_record[target_field] = record[source_field]\n",
    "                \n",
    "                mapped_data.append(mapped_record)\n",
    "            \n",
    "            return mapped_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error mapping data with Gemini: {str(e)}\")\n",
    "            # Fallback to basic field name matching\n",
    "            return self._basic_field_mapping(data, target_schema)\n",
    "    \n",
    "    def _basic_field_mapping(self, \n",
    "                             data: List[Dict[str, Any]], \n",
    "                             target_schema: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Fallback method to perform basic field mapping based on field name similarity.\n",
    "        \n",
    "        Args:\n",
    "            data: List of data records from the ERP system\n",
    "            target_schema: Target schema name\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries in the standardized format\n",
    "        \"\"\"\n",
    "        standard_template = self.standard_schemas[target_schema]\n",
    "        mapped_data = []\n",
    "        \n",
    "        for record in data:\n",
    "            mapped_record = dict(standard_template)  # Start with empty template\n",
    "            \n",
    "            # Map fields based on similar field names\n",
    "            for source_field in record:\n",
    "                source_field_lower = source_field.lower()\n",
    "                \n",
    "                # Try direct mapping first\n",
    "                if source_field_lower in standard_template:\n",
    "                    mapped_record[source_field_lower] = record[source_field]\n",
    "                    continue\n",
    "                    \n",
    "                # Try matching field names\n",
    "                for target_field in standard_template:\n",
    "                    # Check if source field contains the target field or vice versa\n",
    "                    if (target_field in source_field_lower or \n",
    "                        source_field_lower in target_field or\n",
    "                        self._calculate_similarity(source_field_lower, target_field) > 0.7):\n",
    "                        mapped_record[target_field] = record[source_field]\n",
    "                        break\n",
    "            \n",
    "            mapped_data.append(mapped_record)\n",
    "        \n",
    "        return mapped_data\n",
    "    \n",
    "    def _calculate_similarity(self, str1: str, str2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate string similarity between two strings.\n",
    "        \n",
    "        Args:\n",
    "            str1: First string\n",
    "            str2: Second string\n",
    "            \n",
    "        Returns:\n",
    "            Float value between 0 and 1 representing similarity\n",
    "        \"\"\"\n",
    "        # Simple Jaccard similarity implementation\n",
    "        set1 = set(str1)\n",
    "        set2 = set(str2)\n",
    "        \n",
    "        if not set1 or not set2:\n",
    "            return 0.0\n",
    "            \n",
    "        intersection = len(set1.intersection(set2))\n",
    "        union = len(set1.union(set2))\n",
    "        \n",
    "        return intersection / union\n",
    "    \n",
    "    def export_data(self, \n",
    "                    data: List[Dict[str, Any]], \n",
    "                    format_type: str = \"json\", \n",
    "                    output_path: str = None) -> Union[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Export the standardized data to the specified format.\n",
    "        \n",
    "        Args:\n",
    "            data: List of standardized data records\n",
    "            format_type: Output format ('json', 'csv', 'excel', 'df')\n",
    "            output_path: Optional path to save the output file\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved file, DataFrame, or JSON string depending on format_type\n",
    "        \"\"\"\n",
    "        if not data:\n",
    "            print(\"No data to export.\")\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            if format_type.lower() == \"json\":\n",
    "                if output_path:\n",
    "                    with open(output_path, 'w') as f:\n",
    "                        json.dump(data, f, indent=2)\n",
    "                    return output_path\n",
    "                else:\n",
    "                    return json.dumps(data, indent=2)\n",
    "                    \n",
    "            elif format_type.lower() == \"csv\":\n",
    "                df = pd.DataFrame(data)\n",
    "                if output_path:\n",
    "                    df.to_csv(output_path, index=False)\n",
    "                    return output_path\n",
    "                else:\n",
    "                    return df\n",
    "                    \n",
    "            elif format_type.lower() == \"excel\":\n",
    "                if not output_path:\n",
    "                    output_path = \"erp_data_export.xlsx\"\n",
    "                df = pd.DataFrame(data)\n",
    "                df.to_excel(output_path, index=False)\n",
    "                return output_path\n",
    "                \n",
    "            elif format_type.lower() == \"df\":\n",
    "                return pd.DataFrame(data)\n",
    "                \n",
    "            else:\n",
    "                print(f\"Unsupported export format: {format_type}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting data: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_and_map(self, \n",
    "                        data_type: str, \n",
    "                        target_schema: str, \n",
    "                        query_params: Dict[str, Any] = None, \n",
    "                        export_format: str = \"json\", \n",
    "                        output_path: str = None) -> Union[str, pd.DataFrame, List[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Extract data from the ERP system, map it to the standard schema, and optionally export it.\n",
    "        \n",
    "        Args:\n",
    "            data_type: Type of data to extract (e.g., 'customers', 'products', 'invoices')\n",
    "            target_schema: Target schema name\n",
    "            query_params: Optional parameters to filter the data\n",
    "            export_format: Output format ('json', 'csv', 'excel', 'df')\n",
    "            output_path: Optional path to save the output file\n",
    "            \n",
    "        Returns:\n",
    "            Exported data in the specified format\n",
    "        \"\"\"\n",
    "        # Extract data from ERP\n",
    "        raw_data = self.extract_data(data_type, query_params)\n",
    "        \n",
    "        if not raw_data:\n",
    "            print(f\"No {data_type} data extracted from {self.erp_type}.\")\n",
    "            return None\n",
    "            \n",
    "        # Map data to standard schema\n",
    "        mapped_data = self.map_data_with_gemini(raw_data, target_schema)\n",
    "        \n",
    "        # Export data if format is specified\n",
    "        if export_format and export_format.lower() != \"none\":\n",
    "            return self.export_data(mapped_data, export_format, output_path)\n",
    "        else:\n",
    "            return mapped_data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the mapper\n",
    "    mapper = ERPDataMapper()\n",
    "    \n",
    "    # Connect to an ERP system\n",
    "    connection_params = {\n",
    "        \"server\": \"erp.example.com\",\n",
    "        \"username\": \"api_user\",\n",
    "        \"password\": \"api_password\",\n",
    "        \"database\": \"prod_db\"\n",
    "    }\n",
    "    mapper.connect_to_erp(\"sap\", connection_params)\n",
    "    \n",
    "    # Extract and map customer data\n",
    "    customer_data = mapper.extract_and_map(\n",
    "        data_type=\"customers\",\n",
    "        target_schema=\"customer\",\n",
    "        export_format=\"json\",\n",
    "        output_path=\"standardized_customers.json\"\n",
    "    )\n",
    "    \n",
    "    # Extract and map product data\n",
    "    product_data = mapper.extract_and_map(\n",
    "        data_type=\"products\",\n",
    "        target_schema=\"product\",\n",
    "        export_format=\"csv\",\n",
    "        output_path=\"standardized_products.csv\"\n",
    "    )\n",
    "    \n",
    "    # Extract and map invoice data\n",
    "    invoice_data = mapper.extract_and_map(\n",
    "        data_type=\"invoices\",\n",
    "        target_schema=\"invoice\",\n",
    "        export_format=\"excel\",\n",
    "        output_path=\"standardized_invoices.xlsx\"\n",
    "    )\n",
    "    \n",
    "    print(\"Data extraction and mapping completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ccea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
